{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Churn Prediction Pipeline (Free Edition)\n",
    "Pipeline completo de previs√£o de churn em PySpark, adaptado para rodar na vers√£o gratuita do Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ingest√£o de Dados (Silver Layer)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ChurnPredictionPipeline\").getOrCreate()\n",
    "\n",
    "silver_path = \"/Volumes/workspace/voc/churn/churn_silver_2025.csv\"\n",
    "df_silver = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(silver_path)\n",
    "df_silver.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transforma√ß√£o e Feature Engineering (Gold Layer)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_gold = df_silver.withColumn(\"taxa_uso_valor\", col(\"total_logs_app_30d\") / col(\"valor_mensalidade\"))\n",
    "df_gold = df_gold.withColumn(\"label\", col(\"churn\").cast(\"integer\"))\n",
    "\n",
    "df_gold = df_gold.withColumn(\n",
    "    \"categoria_index\",\n",
    "    when(col(\"categoria_principal_voc\") == \"API\", 0)\n",
    "    .when(col(\"categoria_principal_voc\") == \"BUGS\", 1)\n",
    "    .when(col(\"categoria_principal_voc\") == \"SUPORTE\", 2)\n",
    "    .when(col(\"categoria_principal_voc\") == \"FINANCEIRO\", 3)\n",
    "    .otherwise(4)\n",
    ")\n",
    "df_gold.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepara√ß√£o dos Dados para Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_cols = [\"valor_mensalidade\", \"total_logs_app_30d\", \"tickets_suporte_abertos\", \"score_sentimento_voc\", \"taxa_uso_valor\", \"categoria_index\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "df_ml = assembler.transform(df_gold)\n",
    "df_ml.select(\"id_cliente\", \"features\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Treinamento do Modelo (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "train, test = df_ml.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", probabilityCol=\"probability\", predictionCol=\"prediction\")\n",
    "model = rf.fit(train)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "predictions.select(\"id_cliente\", \"probability\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Avalia√ß√£o do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_acc.evaluate(predictions)\n",
    "\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator_auc.evaluate(predictions)\n",
    "\n",
    "print(f\"Acur√°cia: {accuracy}\")\n",
    "print(f\"AUC-ROC: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sa√≠da Final (Gold Layer)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "extract_prob = udf(lambda v: float(v[1]), DoubleType())\n",
    "churn_predictions_gold = predictions.withColumn(\"prob_churn\", extract_prob(col(\"probability\"))) \\\n",
    "    .select(\"id_cliente\", \"prob_churn\", \"prediction\")\n",
    "\n",
    "churn_predictions_gold.show(10)"
   ]
  }
 ]
}
