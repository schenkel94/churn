{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Pipeline de Churn Prediction - Arquitetura Medallion\n",
        "\n",
        "Este notebook simula a transi√ß√£o da camada **Silver** para a **Gold**, aplicando engenharia de atributos (Feature Engineering) e treinando um modelo de Machine Learning para prever o cancelamento de clientes (Churn). Foi otimizado para a infraestrutura do Databricks Free Edition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Instala√ß√£o e Importa√ß√£o de Bibliotecas\n",
        "O Databricks j√° possui o PySpark nativamente, mas vamos importar as fun√ß√µes necess√°rias para o nosso pipeline de ML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col, datediff, current_date, to_date\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Ingest√£o de Dados (Camada Silver)\n",
        "Nesta etapa, carregamos os dados j√° limpos e estruturados da nossa tabela (ou arquivo CSV) na camada Silver."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lendo o CSV mapeado no Unity Catalog / Volumes (Camada Silver)\n",
        "file_path = \"/Volumes/workspace/voc/churn/churn_silver_2025.csv\"\n",
        "\n",
        "df_silver = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "display(df_silver.limit(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Tratamento e Feature Engineering (Silver ‚û°Ô∏è Gold)\n",
        "Criaremos novas vari√°veis (features) que ajudar√£o o algoritmo a encontrar padr√µes.\n",
        "* **taxa_uso_valor**: Rela√ß√£o entre os logs de uso e a mensalidade paga.\n",
        "* **dias_desde_assinatura**: O tempo de vida (tenure) do cliente na base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_gold_prep = df_silver.withColumn(\n",
        "    \"taxa_uso_valor\", \n",
        "    col(\"total_logs_app_30d\") / (col(\"valor_mensalidade\") + 0.01) # Evita divis√£o por zero\n",
        ").withColumn(\n",
        "    \"dias_desde_assinatura\", \n",
        "    datediff(current_date(), to_date(col(\"data_assinatura\")))\n",
        ").na.drop() # Tratamento b√°sico de eventuais nulos\n",
        "\n",
        "display(df_gold_prep.limit(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Prepara√ß√£o para Machine Learning\n",
        "Modelos precisam de n√∫meros para operar. Aqui convertemos textos para √≠ndices e agrupamos todas as vari√°veis num vetor de caracter√≠sticas (`features`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tratamento da Vari√°vel Categ√≥rica\n",
        "indexer = StringIndexer(inputCol=\"categoria_principal_voc\", outputCol=\"categoria_indexada\", handleInvalid=\"keep\")\n",
        "df_indexed = indexer.fit(df_gold_prep).transform(df_gold_prep)\n",
        "\n",
        "# Vetoriza√ß√£o das Features\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"valor_mensalidade\", \"total_logs_app_30d\", \"tickets_suporte_abertos\", \n",
        "               \"score_sentimento_voc\", \"taxa_uso_valor\", \"dias_desde_assinatura\", \"categoria_indexada\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df_features = assembler.transform(df_indexed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Divis√£o de Dados e Treinamento do Modelo\n",
        "Separamos **80% dos dados para treino** e **20% para teste**. Em seguida, instanciamos o `RandomForestClassifier`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split de Treino e Teste\n",
        "train_data, test_data = df_features.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Treinamento do Random Forest\n",
        "# Par√¢metros enxutos (numTrees=50, maxDepth=5) para rodar suavemente na Free Edition\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"churn\", numTrees=50, maxDepth=5, seed=42)\n",
        "rf_model = rf.fit(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Avalia√ß√£o do Modelo\n",
        "Testamos a qualidade da nossa IA em dados n√£o vistos previamente utilizando duas m√©tricas de classifica√ß√£o robustas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = rf_model.transform(test_data)\n",
        "\n",
        "# C√°lculo da AUC-ROC\n",
        "evaluator_roc = BinaryClassificationEvaluator(labelCol=\"churn\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "auc_roc = evaluator_roc.evaluate(predictions)\n",
        "\n",
        "# C√°lculo da Acur√°cia\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"churn\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator_acc.evaluate(predictions)\n",
        "\n",
        "print(\"=\" * 30)\n",
        "print(f\"üìä Acur√°cia do Modelo: {accuracy:.4f}\")\n",
        "print(f\"üìà AUC-ROC: {auc_roc:.4f}\")\n",
        "print(\"=\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Gera√ß√£o da Tabela Gold e Conclus√£o\n",
        "A base final `churn_predictions_gold` consolida o `id_cliente`, as probabilidades geradas pelas √°rvores de decis√£o e a classifica√ß√£o bin√°ria final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "churn_predictions_gold = predictions.select(\"id_cliente\", \"probability\", \"prediction\") \\\n",
        "                                    .withColumnRenamed(\"prediction\", \"previsao_churn\")\n",
        "\n",
        "# Visualizando o DataFrame Gold\n",
        "display(churn_predictions_gold)\n",
        "\n",
        "# Em um ambiente produtivo real, o comando abaixo salvaria na camada Gold:\n",
        "# churn_predictions_gold.write.mode(\"overwrite\").saveAsTable(\"gold.churn_predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ‚úÖ Conclus√£o\n",
        "O pipeline foi executado com sucesso! \n",
        "Os dados brutos (Silver) foram higienizados e transformados matematicamente (Feature Eng). Ap√≥s serem indexados e vetorizados, passaram por um classificador de Floresta Aleat√≥ria que identificou o padr√£o de evas√£o. Agora possu√≠mos um Dataframe na camada Gold enriquecido com a probabilidade de evas√£o, pronto para ser plugado em pain√©is ou fluxos de CRM de reten√ß√£o."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
